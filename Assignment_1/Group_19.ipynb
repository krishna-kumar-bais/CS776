{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Spectrogram Classification (Custom CNN Implementation)\n",
    "\n",
    "This notebook implements an **end-to-end training + evaluation + submission** pipeline for music spectrogram classification, using a CNN built entirely **without `torch.nn` high-level layers**. All layers (convolution, pooling, activations, batch norm, dropout, linear) are custom-implemented.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "### Custom Layer Implementations\n",
    "All layers built manually using only PyTorch primitives:\n",
    "- **`CustomConv2d`**: Convolution via `unfold + batch matmul` (no `F.conv2d`)\n",
    "- **`CustomMaxPool2d`**: Max pooling via `unfold + max`\n",
    "- **`CustomBatchNorm2d`**: Batch normalization with running statistics\n",
    "- **`CustomLinear`**: Fully connected layer with manual matrix multiplication\n",
    "- **`CustomDropout`**: Dropout with manual masking\n",
    "- **`leaky_relu`**: LeakyReLU activation function\n",
    "\n",
    "### Triple-Branch CNN Architecture\n",
    "```\n",
    "Input: 3 images (96×96×3 each)\n",
    "    ↓\n",
    "Branch 1, 2, 3 (independent):\n",
    "  - Block 1: Conv(3→16) → BN(Batch Normalisation) → LeakyReLU → MaxPool → Dropout(0.00)\n",
    "  - Block 2: Conv(16→32) → BN → LeakyReLU → MaxPool → Dropout(0.05)\n",
    "  - Block 3: Conv(32→48) → BN → LeakyReLU → MaxPool → Dropout(0.08)\n",
    "  - Block 4: Conv(48→64) → BN → LeakyReLU → MaxPool → Dropout(0.10)\n",
    "  - Block 5: Conv(64→64) → BN → LeakyReLU → Dropout(0.10)\n",
    "  - Global Average Pooling → 64 features\n",
    "    ↓\n",
    "Concatenate: 3 × 64 = 192 features\n",
    "    ↓\n",
    "Fusion Head:\n",
    "  - Linear(192→128) → LeakyReLU → Dropout(0.30)\n",
    "  - Linear(128→16) → Logits\n",
    "```\n",
    "**Key Features**:\n",
    "- Progressive dropout schedule (0% → 10% through depth)\n",
    "- Global average pooling for parameter efficiency\n",
    "- ~278K parameters (well under 500K limit)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation History\n",
    "\n",
    "### Evolution to Final Architecture\n",
    "\n",
    "**Experiment 1: Initial Baseline (Macro F1 = 0.4893)**\n",
    "- **Image size**: 64×64\n",
    "- **Activation**: ReLU\n",
    "- **Epochs**: 10\n",
    "- **Architecture**: Triple-branch CNN with basic blocks\n",
    "- **Regularization**: None\n",
    "- **Results**: Poor performance, underfitting\n",
    "- **Key Issues**: \n",
    "  - Small image size lost important spectral details\n",
    "  - ReLU caused dying neuron problems\n",
    "  - Insufficient training time\n",
    "  - No regularization led to poor generalization\n",
    "\n",
    "**Experiment 2: Improved Architecture (Macro F1 ≈ 0.876)**\n",
    "- **Image size**: 96×96 (increased from 64×64)\n",
    "- **Activation**: LeakyReLU (replaced ReLU)\n",
    "- **Epochs**: 30 (increased from 10)\n",
    "- **Regularization**: Added\n",
    "  - Batch normalization after each conv layer\n",
    "  - Label smoothing (0.1)\n",
    "  - Progressive dropout (0.0 → 0.1)\n",
    "  - Weight decay (1e-4)\n",
    "- **Results**: Major improvement in performance\n",
    "- **Key Improvements**:\n",
    "  - Larger images preserved spectral details\n",
    "  - LeakyReLU prevented dying neurons\n",
    "  - More epochs allowed better convergence\n",
    "  - Regularization improved generalization\n",
    "\n",
    "**Experiment 3: Extended Training (Macro F1 = 0.89)**\n",
    "- **Image size**: 96×96\n",
    "- **Activation**: LeakyReLU\n",
    "- **Epochs**: 40 \n",
    "- **Regularization**: Same as Experiment 2\n",
    "- **Additional changes**:\n",
    "  - Added OneCycleLR scheduler\n",
    "  - Gradient clipping (1.0)\n",
    "- **Results**: Further improvement from extended training\n",
    "- **Key Insight**: Model still improving, not saturated\n",
    "\n",
    "**Experiment 4: Final Architecture (Macro F1 ≈ 0.90)** ✓\n",
    "- **Image size**: 96×96\n",
    "- **Activation**: LeakyReLU\n",
    "- **Epochs**: 50 \n",
    "- **Optimization enhancements**:\n",
    "  - OneCycleLR (1e-3 → 3e-3 → 3e-5)\n",
    "  - EMA weight averaging (decay=0.999)\n",
    "- **Regularization**:\n",
    "  - Progressive dropout (0.0 → 0.1 in conv, 0.3 in FC)\n",
    "  - Batch normalization\n",
    "  - Weight decay (1e-4)\n",
    "- **Results**: Best performance achieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing pipeline\n",
    "\n",
    "- **Dataset**: Reads `train/metadata.csv` and `test/metadata.csv`\n",
    "- **Triple-input format**: Loads **three images per sample** (`input_1`, `input_2`, `input_3`)\n",
    "- **Image size**: Resizes to **96×96**\n",
    "- **Augmentation**: Spectrogram-safe transformations only\n",
    "  - Horizontal flip (p=0.5) - safe for time-axis\n",
    "  - SpecAugment (time & frequency masking with p=0.7)\n",
    "  - **No vertical flips or rotations** (would destroy frequency structure)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Details\n",
    "\n",
    "### Hyperparameters\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| **Image Size** | 96×96 | Input resolution |\n",
    "| **Batch Size** | 32 | Training batch size |\n",
    "| **Epochs** | 50 | Total training epochs |\n",
    "| **Optimizer** | Adam | With weight decay |\n",
    "| **Learning Rate** | 1e-3 → 3e-3 | OneCycleLR schedule |\n",
    "| **Weight Decay** | 1e-4 | L2 regularization |\n",
    "| **Label Smoothing** | 0.1 | Prevents overconfidence |\n",
    "| **MixUp Alpha** | 0.3 | Data mixing augmentation |\n",
    "| **Gradient Clip** | 1.0 | Max gradient norm |\n",
    "| **Loss Function** | Cross-entropy | Cross-entropy with label smoothing + MixUp |\n",
    "\n",
    "### Training Strategy\n",
    "- **Loss Function**: Cross-entropy with label smoothing + MixUp\n",
    "- **LR Scheduler**: `OneCycleLR` stepped **per batch**\n",
    "  - Warmup: 30% of training\n",
    "  - Max LR: 3e-3\n",
    "  - Final LR: 3e-5\n",
    "- **Gradient Clipping**: Max norm 1.0 for stability\n",
    "- **EMA**: Exponential moving average (decay=0.999) for smoother weights\n",
    "- **Model Selection**: Best model saved based on **validation macro-F1**\n",
    "\n",
    "### Regularization Techniques\n",
    "1. Progressive dropout (0.0 → 0.10 in conv blocks, 0.30 in FC)\n",
    "2. Label smoothing (0.1)\n",
    "3. MixUp augmentation (α=0.3)\n",
    "4. SpecAugment (time/freq masking)\n",
    "5. Weight decay (1e-4)\n",
    "6. Batch normalization (implicit regularization)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Strategy and metrics\n",
    "\n",
    "After training completes, the notebook prints comprehensive validation metrics:\n",
    "\n",
    "### Reported Metrics\n",
    "- ✅ **Total trainable parameters** (enforces ≤500K constraint)\n",
    "- ✅ **Accuracy**: Overall classification accuracy\n",
    "- ✅ **Macro-Precision**: Average precision across all 16 classes\n",
    "- ✅ **Macro-Recall**: Average recall across all 16 classes\n",
    "- ✅ **Macro-F1**: Primary metric for model selection\n",
    "- ✅ **Confusion Matrix**: 16×16 matrix showing per-class performance\n",
    "\n",
    "### Validation Strategy\n",
    "- **Split**: 15% stratified validation set\n",
    "- **Evaluation**: Using EMA weights \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Strategy\n",
    "\n",
    "We tuned hyperparameters using a **controlled, validation-driven process** with the goal of maximising **validation Macro-F1** on a fixed stratified split, while keeping the model within the **500K parameter constraint**.\n",
    "\n",
    "### Fixed Protocol for Fair Comparison\n",
    "\n",
    "- **Same stratified split every run**: `train_test_split` with fixed random state\n",
    "- **Same random seed**: `SEED=42` for Python/NumPy/PyTorch\n",
    "- **Primary selection metric**: Validation Macro-F1 (not accuracy)\n",
    "- **EMA evaluation**: Model selection based on Macro-F1 evaluated using EMA-smoothed weights (`EMA.apply_to(model)` during validation)\n",
    "- **One change group at a time**: Tune one group (LR, resolution, regularisation, augmentation) while keeping others fixed\n",
    "\n",
    "---\n",
    "\n",
    "### Stage A — Optimisation Stability (Learning Rate + OneCycleLR)\n",
    "\n",
    "Because training uses Adam + OneCycleLR, we tuned the schedule primarily via `MAX_LR` (and kept schedule shape constants unless needed):\n",
    "\n",
    "**Tuned (coarse → fine):**\n",
    "- `MAX_LR ∈ {1e-3, 2e-3, 3e-3}`\n",
    "- Corresponding base LR values: `LR ∈ {3e-4, 7e-4, 1e-3}`\n",
    "\n",
    "**If training showed late-epoch instability/metric drop:**\n",
    "- Reduced `LR`: 1e-3 → 7e-4 → 5e-4\n",
    "- Reduced `MAX_LR`: 3e-3 → 2e-3 → 1.5e-3\n",
    "\n",
    "**Scheduler shape (tuned only if needed):**\n",
    "- `pct_start ∈ {0.2, 0.3, 0.4}`\n",
    "- `final_div_factor ∈ {50, 100, 200}`\n",
    "\n",
    "**Selection rule:** Choose the setting with the best EMA Macro-F1 and smooth training (no degradation), then confirm in a full 50-epoch run.\n",
    "\n",
    "### Stage B — Input Resolution (IMG_SIZE) with Batch Size Scaling\n",
    "\n",
    "Since the model uses global average pooling in each branch (`global_avg_pool`), increasing `IMG_SIZE` does not increase FC input size. We tested:\n",
    "\n",
    "**Resolutions tested:**\n",
    "- `IMG_SIZE ∈ {96, 112, 128}`\n",
    "\n",
    "**Adjusted BATCH_SIZE for GPU memory:**\n",
    "- 96 → 32\n",
    "- 112 → 24–32\n",
    "- 128 → 16–24\n",
    "\n",
    "**Selection rule:** Pick the resolution that improves Macro-F1 **without overfitting** (Macro-F1 plateaus or drops while train loss keeps decreasing).\n",
    "\n",
    "\n",
    "### Stage C — Regularisation (Generalisation Control)\n",
    "\n",
    "We tuned regularisation to improve Macro-F1 (especially hard classes) and reduce overfitting:\n",
    "\n",
    "**Parameters tuned:**\n",
    "- `WD ∈ {5e-5, 1e-4, 2e-4}` (weight decay)\n",
    "- `LABEL_SMOOTH ∈ {0.05, 0.10, 0.15}` (applied inside `F.cross_entropy(..., label_smoothing=...)`)\n",
    "- `GRAD_CLIP ∈ {0.5, 1.0}` (keep 1.0 unless gradients spike)\n",
    "\n",
    "**Selection rule:** Choose the combination that improves Macro-F1 and macro-recall, **not just accuracy**.\n",
    "\n",
    "\n",
    "### Stage D — Augmentation and Robustness (SpecAugment + MixUp + EMA)\n",
    "\n",
    "We tuned augmentation strength because the task is spectrogram-like and benefits from invariance:\n",
    "\n",
    "**SpecAugment (implemented in dataset):**\n",
    "- `(time_mask, freq_mask) ∈ {(12,12), (16,16)}`\n",
    "- `p ∈ {0.5, 0.7, 0.85}`\n",
    "\n",
    "**MixUp:**\n",
    "- `MIX_ALPHA ∈ {0.2, 0.3, 0.4}`\n",
    "\n",
    "**EMA decay:**\n",
    "- `decay ∈ {0.998, 0.999}`\n",
    "\n",
    "**Selection rule:** Prioritise the config that reduces validation confusion (confusion matrix) and raises Macro-F1 **consistently across epochs**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference & Submission\n",
    "\n",
    "### Test Set Processing\n",
    "1. Loads test metadata from `test/metadata.csv`\n",
    "2. Applies same preprocessing as validation (**no augmentation**)\n",
    "3. Runs inference using best EMA model\n",
    "4. Generates predictions in **exact metadata order**\n",
    "\n",
    "### Submission File Creation\n",
    "- **Format**: CSV with columns `id,target`\n",
    "- **Output**: `/kaggle/working/submission96.csv`\n",
    "- **Ordering**: Preserves original test set order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on Validation dataset\n",
    "\n",
    "### Validation Performance\n",
    "Total trainable parameters: 278,912\n",
    "- **Macro-F1**:  0.927060\n",
    "- **Accuracy**:  0.932498\n",
    "- **Macro-Precision**: 0.929580\n",
    "- **Macro-Recall**: 0.925461\n",
    "- **Training Time**: ~2 hours on Kaggle GPU (50 epochs)\n",
    "\n",
    "### Model Characteristics\n",
    "- **Architecture**: Triple-branch CNN with late fusion\n",
    "- **Parameters**: 278,912\n",
    "- **Regularization**: Progressive dropout + MixUp + Augmentation + EMA\n",
    "- **Efficiency**: Global average pooling reduces parameters significantly\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Contributions\n",
    "\n",
    "**Group 19**\n",
    "\n",
    "| Name | Email | Contributions |\n",
    "|------|-------|--------------|\n",
    "| Sontam Deekshitha | sontamd22@iitk.ac.in | 14.29% |\n",
    "| Mahathi Garapati | gnagal22@iitk.ac.in | 14.29% |\n",
    "| Maradana Kasi Sri Roshan | mkasi22@iitk.ac.in | 14.29% |\n",
    "| Chintapudi Gowtham Chand | cgchand22@iitk.ac.in | 14.29% |\n",
    "| Krishna Kumar Bais | krishnakb24@iitk.ac.in | 14.29% |\n",
    "| Sevak Baliram Shekokar | bssevak24@iitk.ac.in | 14.29% |\n",
    "| Daksh Kumar Singh | dakshks22@iitk.ac.in | 14.29%|\n",
    "\n",
    "**Team Coordination**: All members of the team contributed equally\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-06T15:44:29.382141Z",
     "iopub.status.busy": "2026-02-06T15:44:29.381963Z",
     "iopub.status.idle": "2026-02-06T15:44:37.654445Z",
     "shell.execute_reply": "2026-02-06T15:44:37.653829Z",
     "shell.execute_reply.started": "2026-02-06T15:44:29.382121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, math, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reproducibility, Device, and Dataset Path Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:44:50.372015Z",
     "iopub.status.busy": "2026-02-06T15:44:50.371252Z",
     "iopub.status.idle": "2026-02-06T15:44:50.445879Z",
     "shell.execute_reply": "2026-02-06T15:44:50.445147Z",
     "shell.execute_reply.started": "2026-02-06T15:44:50.371984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Detected DATA_ROOT: /kaggle/input/music-dataset/dataset_music\n",
      "TRAIN_META: /kaggle/input/music-dataset/dataset_music/train/metadata.csv\n",
      "TEST_META : /kaggle/input/music-dataset/dataset_music/test/metadata.csv\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Choose device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "def find_dataset_music_root():\n",
    "    \"\"\"\n",
    "    Automatically finds the dataset root directory in Kaggle's input folder.\n",
    "    Handles different possible folder structures.\n",
    "    \"\"\"\n",
    "    base = \"/kaggle/input\"\n",
    "    if not os.path.exists(base):\n",
    "        raise FileNotFoundError(\"/kaggle/input not found. Are you running on Kaggle?\")\n",
    "\n",
    "    candidates = []\n",
    "    for d in os.listdir(base):\n",
    "        p = os.path.join(base, d)\n",
    "        if not os.path.isdir(p):\n",
    "            continue\n",
    "\n",
    "        # Check if dataset_music subfolder exists\n",
    "        cand1 = os.path.join(p, \"dataset_music\")\n",
    "        if os.path.exists(os.path.join(cand1, \"train\", \"metadata.csv\")) and os.path.exists(os.path.join(cand1, \"test\", \"metadata.csv\")):\n",
    "            candidates.append(cand1)\n",
    "\n",
    "        # Check if train/test folders are directly in this directory\n",
    "        if os.path.exists(os.path.join(p, \"train\", \"metadata.csv\")) and os.path.exists(os.path.join(p, \"test\", \"metadata.csv\")):\n",
    "            candidates.append(p)\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        # Debug: print what's actually in /kaggle/input\n",
    "        print(\"Could not auto-detect dataset root. Contents of /kaggle/input:\")\n",
    "        for d in os.listdir(base):\n",
    "            print(\" -\", d)\n",
    "        raise FileNotFoundError(\"No folder found containing train/metadata.csv and test/metadata.csv\")\n",
    "\n",
    "    # Return the first valid match\n",
    "    return candidates[0]\n",
    "\n",
    "DATA_ROOT = find_dataset_music_root()\n",
    "TRAIN_META = os.path.join(DATA_ROOT, \"train\", \"metadata.csv\")\n",
    "TEST_META  = os.path.join(DATA_ROOT, \"test\", \"metadata.csv\")\n",
    "\n",
    "print(\"Detected DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"TRAIN_META:\", TRAIN_META)\n",
    "print(\"TEST_META :\", TEST_META)\n",
    "\n",
    "assert os.path.exists(TRAIN_META), f\"TRAIN_META not found: {TRAIN_META}\"\n",
    "assert os.path.exists(TEST_META),  f\"TEST_META not found:  {TEST_META}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image Preprocessing Utilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:44:58.234046Z",
     "iopub.status.busy": "2026-02-06T15:44:58.233650Z",
     "iopub.status.idle": "2026-02-06T15:44:58.241386Z",
     "shell.execute_reply": "2026-02-06T15:44:58.240777Z",
     "shell.execute_reply.started": "2026-02-06T15:44:58.234021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "def pil_resize(img, size):\n",
    "    \"\"\"Resize image to square dimension\"\"\"\n",
    "    return img.resize((size, size), Image.BILINEAR)\n",
    "\n",
    "def pil_hflip(img, p=0.5):\n",
    "    \"\"\"Horizontal flip with probability p (safe for spectrograms)\"\"\"\n",
    "    if random.random() < p:\n",
    "        return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return img\n",
    "\n",
    "def pil_to_tensor_norm(img):\n",
    "    \"\"\"Convert PIL image to normalized tensor\"\"\"\n",
    "    arr = np.asarray(img).astype(np.float32) / 255.0\n",
    "    arr = (arr - MEAN) / STD\n",
    "    arr = np.transpose(arr, (2,0,1))\n",
    "    return torch.tensor(arr, dtype=torch.float32)\n",
    "\n",
    "def spec_augment(x, time_mask=12, freq_mask=12, p=0.7):\n",
    "    \"\"\"\n",
    "    SpecAugment: randomly mask time and frequency bands.\n",
    "    This helps the model generalize better to spectrograms.\n",
    "    \"\"\"\n",
    "    if random.random() > p:\n",
    "        return x\n",
    "    C, H, W = x.shape\n",
    "\n",
    "    # Frequency masking (vertical strips)\n",
    "    fm = random.randint(0, freq_mask)\n",
    "    if fm > 0 and H > fm:\n",
    "        f0 = random.randint(0, H - fm)\n",
    "        x[:, f0:f0+fm, :] = 0\n",
    "\n",
    "    # Time masking (horizontal strips)\n",
    "    tm = random.randint(0, time_mask)\n",
    "    if tm > 0 and W > tm:\n",
    "        t0 = random.randint(0, W - tm)\n",
    "        x[:, :, t0:t0+tm] = 0\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:45:12.759891Z",
     "iopub.status.busy": "2026-02-06T15:45:12.759597Z",
     "iopub.status.idle": "2026-02-06T15:45:12.769610Z",
     "shell.execute_reply": "2026-02-06T15:45:12.769012Z",
     "shell.execute_reply.started": "2026-02-06T15:45:12.759837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MusicTripleDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads three images per sample (input_1, input_2, input_3).\n",
    "    Handles both training set (with labels) and test set (without labels).\n",
    "    \"\"\"\n",
    "    def __init__(self, meta_csv, img_size=96, is_train=True, df=None):\n",
    "        self.meta_csv = meta_csv\n",
    "        self.img_size = img_size\n",
    "        self.is_train = is_train\n",
    "\n",
    "        if df is None:\n",
    "            self.df = pd.read_csv(meta_csv)\n",
    "        else:\n",
    "            self.df = df.reset_index(drop=True)\n",
    "\n",
    "        # Handle different column names for train vs test\n",
    "        self.col1 = \"input_1_path\" if \"input_1_path\" in self.df.columns else \"input_1\"\n",
    "        self.col2 = \"input_2\"\n",
    "        self.col3 = \"input_3\"\n",
    "        self.has_labels = \"target\" in self.df.columns\n",
    "\n",
    "        # Base directory for resolving relative paths\n",
    "        self.base_root = os.path.dirname(os.path.dirname(meta_csv))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _resolve_path(self, p):\n",
    "        \"\"\"\n",
    "        Handles various path formats in the metadata CSV.\n",
    "        Tries multiple strategies to find the actual file.\n",
    "        \"\"\"\n",
    "        p = str(p).strip()\n",
    "        if os.path.isabs(p) and os.path.exists(p):\n",
    "            return p\n",
    "\n",
    "        # Try relative to current working directory\n",
    "        p1 = os.path.normpath(os.path.join(os.getcwd(), p))\n",
    "        if os.path.exists(p1):\n",
    "            return p1\n",
    "\n",
    "        # Strip common prefixes and try relative to base_root\n",
    "        rel = p.replace(\"./\", \"\")\n",
    "        rel = rel.replace(\"dataset_music/\", \"\")\n",
    "        p2 = os.path.join(self.base_root, rel)\n",
    "        if os.path.exists(p2):\n",
    "            return p2\n",
    "\n",
    "        # Last resort: just join with base_root\n",
    "        p3 = os.path.join(self.base_root, p)\n",
    "        return p3\n",
    "\n",
    "    def _load_one(self, path):\n",
    "        \"\"\"Load and preprocess a single image\"\"\"\n",
    "        fp = self._resolve_path(path)\n",
    "        img = Image.open(fp).convert(\"RGB\")\n",
    "        img = pil_resize(img, self.img_size)\n",
    "        if self.is_train:\n",
    "            img = pil_hflip(img, p=0.5)\n",
    "        x = pil_to_tensor_norm(img)\n",
    "        if self.is_train:\n",
    "            x = spec_augment(x, time_mask=12, freq_mask=12, p=0.7)\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        x1 = self._load_one(row[self.col1])\n",
    "        x2 = self._load_one(row[self.col2])\n",
    "        x3 = self._load_one(row[self.col3])\n",
    "        if self.has_labels:\n",
    "            y = int(row[\"target\"])\n",
    "            return x1, x2, x3, torch.tensor(y, dtype=torch.long)\n",
    "        return x1, x2, x3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers - Activation, Dropout, Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:45:18.253753Z",
     "iopub.status.busy": "2026-02-06T15:45:18.253440Z",
     "iopub.status.idle": "2026-02-06T15:45:18.262106Z",
     "shell.execute_reply": "2026-02-06T15:45:18.261421Z",
     "shell.execute_reply.started": "2026-02-06T15:45:18.253722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, neg=0.01):\n",
    "    \"\"\"LeakyReLU activation (prevents dying neurons)\"\"\"\n",
    "    return torch.where(x > 0, x, neg * x)\n",
    "\n",
    "class CustomDropout(nn.Module):\n",
    "    \"\"\"Dropout layer built manually\"\"\"\n",
    "    def __init__(self, p=0.3):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if (not self.training) or self.p <= 0:\n",
    "            return x\n",
    "        keep = 1.0 - self.p\n",
    "        mask = (torch.rand_like(x) < keep).float() / keep\n",
    "        return x * mask\n",
    "\n",
    "class CustomBatchNorm2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Batch normalization for 2D feature maps.\n",
    "    Normalizes across batch and spatial dimensions.\n",
    "    \"\"\"\n",
    "    def __init__(self, c, eps=1e-5, momentum=0.1):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.gamma = nn.Parameter(torch.ones(c))\n",
    "        self.beta  = nn.Parameter(torch.zeros(c))\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(c))\n",
    "        self.register_buffer(\"running_var\",  torch.ones(c))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # Compute batch statistics\n",
    "            mean = x.mean(dim=(0,2,3))\n",
    "            var  = x.var(dim=(0,2,3), unbiased=False)\n",
    "            # Update running statistics\n",
    "            with torch.no_grad():\n",
    "                self.running_mean.mul_(1-self.momentum).add_(mean, alpha=self.momentum)\n",
    "                self.running_var.mul_(1-self.momentum).add_(var,  alpha=self.momentum)\n",
    "        else:\n",
    "            # Use running statistics during eval\n",
    "            mean = self.running_mean\n",
    "            var  = self.running_var\n",
    "\n",
    "        # Normalize and apply learnable affine transform\n",
    "        xhat = (x - mean.view(1,-1,1,1)) / torch.sqrt(var.view(1,-1,1,1) + self.eps)\n",
    "        return xhat * self.gamma.view(1,-1,1,1) + self.beta.view(1,-1,1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers - Convolution and Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:45:22.655332Z",
     "iopub.status.busy": "2026-02-06T15:45:22.654371Z",
     "iopub.status.idle": "2026-02-06T15:45:22.665206Z",
     "shell.execute_reply": "2026-02-06T15:45:22.664610Z",
     "shell.execute_reply.started": "2026-02-06T15:45:22.655296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    2D convolution using unfold and batch matrix multiplication.\n",
    "    Implements convolution without using torch.nn.Conv2d.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, k=3, stride=1, padding=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.out_c = out_c\n",
    "        self.k = k\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        # He initialization (good for ReLU-like activations)\n",
    "        fan_in = in_c * k * k\n",
    "        w = torch.randn(out_c, in_c, k, k) * math.sqrt(2.0 / fan_in)\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(out_c)) if bias else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # Add padding if needed\n",
    "        if self.padding > 0:\n",
    "            x = F.pad(x, (self.padding, self.padding, self.padding, self.padding))\n",
    "        \n",
    "        # Extract patches using unfold\n",
    "        patches = F.unfold(x, kernel_size=self.k, stride=self.stride)  # (B, C*k*k, L)\n",
    "        CK2 = patches.size(1)\n",
    "        \n",
    "        # Reshape weight for matrix multiplication\n",
    "        Wmat = self.weight.view(self.out_c, CK2).unsqueeze(0).expand(B, -1, -1)  # (B, out_c, CK2)\n",
    "        \n",
    "        # Compute convolution via batch matmul\n",
    "        out = torch.bmm(Wmat, patches)  # (B, out_c, L)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias.view(1, self.out_c, 1)\n",
    "        \n",
    "        # Reshape back to 2D feature map\n",
    "        Hp, Wp = x.shape[2], x.shape[3]\n",
    "        Hout = (Hp - self.k)//self.stride + 1\n",
    "        Wout = (Wp - self.k)//self.stride + 1\n",
    "        return out.view(B, self.out_c, Hout, Wout)\n",
    "\n",
    "class CustomMaxPool2d(nn.Module):\n",
    "    \"\"\"Max pooling using unfold and max operation\"\"\"\n",
    "    def __init__(self, k=2, stride=2, padding=0):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.padding > 0:\n",
    "            x = F.pad(x, (self.padding, self.padding, self.padding, self.padding), value=float(\"-inf\"))\n",
    "        \n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # Extract patches\n",
    "        patches = F.unfold(x, kernel_size=self.k, stride=self.stride)  # (B, C*k*k, L)\n",
    "        L = patches.size(2)\n",
    "        patches = patches.view(B, C, self.k*self.k, L)\n",
    "        \n",
    "        # Take max over each patch\n",
    "        out, _ = patches.max(dim=2)  # (B, C, L)\n",
    "        \n",
    "        # Reshape to 2D\n",
    "        Hout = (H - self.k)//self.stride + 1\n",
    "        Wout = (W - self.k)//self.stride + 1\n",
    "        return out.view(B, C, Hout, Wout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers - Fully Connected and Global Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:45:30.623234Z",
     "iopub.status.busy": "2026-02-06T15:45:30.622965Z",
     "iopub.status.idle": "2026-02-06T15:45:30.628893Z",
     "shell.execute_reply": "2026-02-06T15:45:30.628073Z",
     "shell.execute_reply.started": "2026-02-06T15:45:30.623214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomLinear(nn.Module):\n",
    "    \"\"\"Fully connected layer built manually\"\"\"\n",
    "    def __init__(self, in_f, out_f, bias=True):\n",
    "        super().__init__()\n",
    "        bound = 1.0 / math.sqrt(in_f)\n",
    "        self.weight = nn.Parameter(torch.empty(out_f, in_f).uniform_(-bound, bound))\n",
    "        self.bias   = nn.Parameter(torch.zeros(out_f)) if bias else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x @ self.weight.t()\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        return y\n",
    "\n",
    "def global_avg_pool(x):\n",
    "    \"\"\"Global average pooling: reduces (B,C,H,W) to (B,C)\"\"\"\n",
    "    return x.mean(dim=(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Blocks and Branch Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:45:34.692312Z",
     "iopub.status.busy": "2026-02-06T15:45:34.691731Z",
     "iopub.status.idle": "2026-02-06T15:45:34.699801Z",
     "shell.execute_reply": "2026-02-06T15:45:34.699074Z",
     "shell.execute_reply.started": "2026-02-06T15:45:34.692284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single convolutional block:\n",
    "    Conv -> BatchNorm -> LeakyReLU -> [optional MaxPool] -> [optional Dropout]\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, pool=True, drop=0.0):\n",
    "        super().__init__()\n",
    "        self.conv = CustomConv2d(in_c, out_c, k=3, stride=1, padding=1, bias=True)\n",
    "        self.bn   = CustomBatchNorm2d(out_c)\n",
    "        self.pool = CustomMaxPool2d(k=2, stride=2) if pool else None\n",
    "        self.drop = CustomDropout(drop) if drop > 0 else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = leaky_relu(x, 0.01)\n",
    "        if self.pool is not None:\n",
    "            x = self.pool(x)\n",
    "        if self.drop is not None:\n",
    "            x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class BranchCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Single branch of the triple-branch architecture.\n",
    "    Five conv blocks with progressive dropout, ending with global average pooling.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b1 = ConvBlock(3, 16, pool=True,  drop=0.00)\n",
    "        self.b2 = ConvBlock(16, 32, pool=True, drop=0.05)\n",
    "        self.b3 = ConvBlock(32, 48, pool=True, drop=0.08)\n",
    "        self.b4 = ConvBlock(48, 64, pool=True, drop=0.10)\n",
    "        self.b5 = ConvBlock(64, 64, pool=False, drop=0.10)  # No pooling in last block\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.b4(x)\n",
    "        x = self.b5(x)\n",
    "        return global_avg_pool(x)  # Output: (B, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:45:39.189542Z",
     "iopub.status.busy": "2026-02-06T15:45:39.189262Z",
     "iopub.status.idle": "2026-02-06T15:45:39.195697Z",
     "shell.execute_reply": "2026-02-06T15:45:39.195046Z",
     "shell.execute_reply.started": "2026-02-06T15:45:39.189519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TripleBranchNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Main model: three independent CNN branches + fusion head.\n",
    "    Each branch processes one input image, then features are concatenated.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=16):\n",
    "        super().__init__()\n",
    "        self.branch1 = BranchCNN()\n",
    "        self.branch2 = BranchCNN()\n",
    "        self.branch3 = BranchCNN()\n",
    "        \n",
    "        # Fusion head: concatenate 3x64 features, then classify\n",
    "        self.fc1 = CustomLinear(64*3, 128)\n",
    "        self.dp  = CustomDropout(0.30)\n",
    "        self.fc2 = CustomLinear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x1, x2, x3):\n",
    "        # Process each input through its own branch\n",
    "        f1 = self.branch1(x1)\n",
    "        f2 = self.branch2(x2)\n",
    "        f3 = self.branch3(x3)\n",
    "        \n",
    "        # Concatenate features\n",
    "        fused = torch.cat([f1, f2, f3], dim=1)\n",
    "        \n",
    "        # Classification head\n",
    "        x = self.fc1(fused)\n",
    "        x = leaky_relu(x, 0.01)\n",
    "        x = self.dp(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "def count_params(model):\n",
    "    \"\"\"Count trainable parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utilities - MixUp and EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:45:53.072742Z",
     "iopub.status.busy": "2026-02-06T15:45:53.072046Z",
     "iopub.status.idle": "2026-02-06T15:45:53.080871Z",
     "shell.execute_reply": "2026-02-06T15:45:53.080154Z",
     "shell.execute_reply.started": "2026-02-06T15:45:53.072705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def mixup_batch(x1, x2, x3, y, alpha=0.3):\n",
    "    \"\"\"\n",
    "    MixUp: create virtual training samples by mixing pairs of examples.\n",
    "    Helps model generalize better by encouraging linear behavior between examples.\n",
    "    \"\"\"\n",
    "    if alpha <= 0:\n",
    "        return x1, x2, x3, y, None\n",
    "    \n",
    "    lam = float(np.random.beta(alpha, alpha))\n",
    "    idx = torch.randperm(x1.size(0), device=x1.device)\n",
    "    y2 = y[idx]\n",
    "    \n",
    "    # Mix the inputs\n",
    "    x1m = lam*x1 + (1-lam)*x1[idx]\n",
    "    x2m = lam*x2 + (1-lam)*x2[idx]\n",
    "    x3m = lam*x3 + (1-lam)*x3[idx]\n",
    "    \n",
    "    return x1m, x2m, x3m, y, (y2, lam)\n",
    "\n",
    "def mixup_loss(logits, y, mix_info=None, label_smoothing=0.1):\n",
    "    \"\"\"Compute loss for possibly-mixed batch\"\"\"\n",
    "    if mix_info is None:\n",
    "        return F.cross_entropy(logits, y, label_smoothing=label_smoothing)\n",
    "    \n",
    "    y2, lam = mix_info\n",
    "    l1 = F.cross_entropy(logits, y,  reduction=\"none\", label_smoothing=label_smoothing)\n",
    "    l2 = F.cross_entropy(logits, y2, reduction=\"none\", label_smoothing=label_smoothing)\n",
    "    return (lam*l1 + (1-lam)*l2).mean()\n",
    "\n",
    "class EMA:\n",
    "    \"\"\"\n",
    "    Maintains exponential moving average of model weights.\n",
    "    This gives us a smoother version of the model that often generalizes better.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def update(self, model):\n",
    "        \"\"\"Update shadow weights after each training step\"\"\"\n",
    "        for k, v in model.state_dict().items():\n",
    "            self.shadow[k].mul_(self.decay).add_(v.detach(), alpha=1.0 - self.decay)\n",
    "    \n",
    "    def apply_to(self, model):\n",
    "        \"\"\"Load EMA weights into model\"\"\"\n",
    "        model.load_state_dict(self.shadow, strict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:46:01.490621Z",
     "iopub.status.busy": "2026-02-06T15:46:01.490085Z",
     "iopub.status.idle": "2026-02-06T15:46:01.497242Z",
     "shell.execute_reply": "2026-02-06T15:46:01.496512Z",
     "shell.execute_reply.started": "2026-02-06T15:46:01.490590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"Run evaluation and compute metrics\"\"\"\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    \n",
    "    for batch in loader:\n",
    "        x1, x2, x3, y = batch\n",
    "        x1, x2, x3 = x1.to(DEVICE), x2.to(DEVICE), x3.to(DEVICE)\n",
    "        logits = model(x1, x2, x3)\n",
    "        p = logits.argmax(dim=1).cpu().numpy()\n",
    "        preds.append(p)\n",
    "        trues.append(y.numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds)\n",
    "    trues = np.concatenate(trues)\n",
    "    \n",
    "    acc = accuracy_score(trues, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(trues, preds, average=\"macro\", zero_division=0)\n",
    "    cm = confusion_matrix(trues, preds)\n",
    "    \n",
    "    return acc, prec, rec, f1, cm\n",
    "\n",
    "def clip_gradients(model, max_norm=1.0):\n",
    "    \"\"\"\n",
    "    Clip gradients by global norm to prevent exploding gradients.\n",
    "    Helps stabilize training, especially early on.\n",
    "    \"\"\"\n",
    "    total = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            n = p.grad.data.norm(2)\n",
    "            total += n.item()**2\n",
    "    total = total**0.5\n",
    "    \n",
    "    if total > max_norm:\n",
    "        scale = max_norm / (total + 1e-6)\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                p.grad.data.mul_(scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:46:05.235134Z",
     "iopub.status.busy": "2026-02-06T15:46:05.234482Z",
     "iopub.status.idle": "2026-02-06T15:46:05.241166Z",
     "shell.execute_reply": "2026-02-06T15:46:05.240355Z",
     "shell.execute_reply.started": "2026-02-06T15:46:05.235104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, scheduler, ema, mix_alpha=0.3, label_smoothing=0.1, grad_clip=1.0):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    \n",
    "    for batch in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        x1, x2, x3, y = batch\n",
    "        x1, x2, x3, y = x1.to(DEVICE), x2.to(DEVICE), x3.to(DEVICE), y.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # Apply MixUp\n",
    "        x1m, x2m, x3m, y1, mix_info = mixup_batch(x1, x2, x3, y, alpha=mix_alpha)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(x1m, x2m, x3m)\n",
    "        loss = mixup_loss(logits, y1, mix_info=mix_info, label_smoothing=label_smoothing)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        clip_gradients(model, max_norm=grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Step scheduler and update EMA\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        if ema is not None:\n",
    "            ema.update(model)\n",
    "        \n",
    "        running += loss.item()\n",
    "    \n",
    "    return running / max(1, len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Training Pipeline and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T15:49:58.589883Z",
     "iopub.status.busy": "2026-02-06T15:49:58.589277Z",
     "iopub.status.idle": "2026-02-06T17:56:24.876098Z",
     "shell.execute_reply": "2026-02-06T17:56:24.875051Z",
     "shell.execute_reply.started": "2026-02-06T15:49:58.589831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 278,912\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/50 | loss=2.3133 | val_acc=0.1726 | macroP=0.0687 | macroR=0.1255 | macroF1=0.0703\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/50 | loss=2.0434 | val_acc=0.2834 | macroP=0.1686 | macroR=0.2277 | macroF1=0.1380\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/50 | loss=1.9162 | val_acc=0.3894 | macroP=0.4551 | macroR=0.3405 | macroF1=0.2884\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/50 | loss=1.8529 | val_acc=0.5287 | macroP=0.5559 | macroR=0.4893 | macroF1=0.4870\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/50 | loss=1.7885 | val_acc=0.6161 | macroP=0.6005 | macroR=0.5811 | macroF1=0.5794\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/50 | loss=1.7509 | val_acc=0.6530 | macroP=0.6343 | macroR=0.6232 | macroF1=0.6198\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/50 | loss=1.7111 | val_acc=0.6799 | macroP=0.6647 | macroR=0.6528 | macroF1=0.6493\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/50 | loss=1.7176 | val_acc=0.7101 | macroP=0.7000 | macroR=0.6863 | macroF1=0.6843\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09/50 | loss=1.6745 | val_acc=0.7327 | macroP=0.7235 | macroR=0.7114 | macroF1=0.7100\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | loss=1.6481 | val_acc=0.7495 | macroP=0.7403 | macroR=0.7302 | macroF1=0.7278\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | loss=1.6179 | val_acc=0.7706 | macroP=0.7629 | macroR=0.7513 | macroF1=0.7515\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | loss=1.6149 | val_acc=0.7908 | macroP=0.7839 | macroR=0.7740 | macroF1=0.7745\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | loss=1.5915 | val_acc=0.8079 | macroP=0.8008 | macroR=0.7916 | macroF1=0.7925\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | loss=1.6140 | val_acc=0.8183 | macroP=0.8133 | macroR=0.8032 | macroF1=0.8053\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | loss=1.5572 | val_acc=0.8207 | macroP=0.8143 | macroR=0.8040 | macroF1=0.8066\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | loss=1.5458 | val_acc=0.8293 | macroP=0.8220 | macroR=0.8111 | macroF1=0.8144\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | loss=1.5113 | val_acc=0.8387 | macroP=0.8337 | macroR=0.8220 | macroF1=0.8256\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | loss=1.5201 | val_acc=0.8439 | macroP=0.8398 | macroR=0.8280 | macroF1=0.8311\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | loss=1.4794 | val_acc=0.8497 | macroP=0.8447 | macroR=0.8339 | macroF1=0.8369\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | loss=1.5005 | val_acc=0.8580 | macroP=0.8522 | macroR=0.8454 | macroF1=0.8472\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | loss=1.4732 | val_acc=0.8601 | macroP=0.8544 | macroR=0.8472 | macroF1=0.8494\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | loss=1.4339 | val_acc=0.8650 | macroP=0.8606 | macroR=0.8527 | macroF1=0.8550\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | loss=1.4552 | val_acc=0.8677 | macroP=0.8629 | macroR=0.8561 | macroF1=0.8579\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | loss=1.4333 | val_acc=0.8717 | macroP=0.8669 | macroR=0.8593 | macroF1=0.8615\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | loss=1.3764 | val_acc=0.8763 | macroP=0.8728 | macroR=0.8640 | macroF1=0.8668\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | loss=1.4150 | val_acc=0.8839 | macroP=0.8800 | macroR=0.8719 | macroF1=0.8744\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | loss=1.3981 | val_acc=0.8839 | macroP=0.8787 | macroR=0.8721 | macroF1=0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | loss=1.3846 | val_acc=0.8870 | macroP=0.8818 | macroR=0.8762 | macroF1=0.8777\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | loss=1.3603 | val_acc=0.8949 | macroP=0.8892 | macroR=0.8852 | macroF1=0.8860\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | loss=1.3631 | val_acc=0.8940 | macroP=0.8891 | macroR=0.8838 | macroF1=0.8852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | loss=1.3393 | val_acc=0.8940 | macroP=0.8909 | macroR=0.8840 | macroF1=0.8862\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | loss=1.2931 | val_acc=0.8989 | macroP=0.8958 | macroR=0.8897 | macroF1=0.8916\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | loss=1.3256 | val_acc=0.9053 | macroP=0.9020 | macroR=0.8958 | macroF1=0.8980\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | loss=1.3160 | val_acc=0.9071 | macroP=0.9034 | macroR=0.8980 | macroF1=0.8999\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | loss=1.2839 | val_acc=0.9108 | macroP=0.9082 | macroR=0.9016 | macroF1=0.9042\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | loss=1.2737 | val_acc=0.9136 | macroP=0.9103 | macroR=0.9050 | macroF1=0.9069\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | loss=1.2370 | val_acc=0.9154 | macroP=0.9119 | macroR=0.9070 | macroF1=0.9086\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | loss=1.2167 | val_acc=0.9172 | macroP=0.9129 | macroR=0.9090 | macroF1=0.9104\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | loss=1.2629 | val_acc=0.9206 | macroP=0.9172 | macroR=0.9134 | macroF1=0.9147\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | loss=1.2248 | val_acc=0.9224 | macroP=0.9195 | macroR=0.9154 | macroF1=0.9170\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | loss=1.2149 | val_acc=0.9236 | macroP=0.9205 | macroR=0.9167 | macroF1=0.9180\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | loss=1.2036 | val_acc=0.9255 | macroP=0.9225 | macroR=0.9184 | macroF1=0.9200\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | loss=1.2163 | val_acc=0.9261 | macroP=0.9235 | macroR=0.9187 | macroF1=0.9207\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | loss=1.1835 | val_acc=0.9267 | macroP=0.9241 | macroR=0.9193 | macroF1=0.9213\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | loss=1.1663 | val_acc=0.9276 | macroP=0.9242 | macroR=0.9201 | macroF1=0.9217\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 | loss=1.1750 | val_acc=0.9285 | macroP=0.9255 | macroR=0.9211 | macroF1=0.9228\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 | loss=1.1678 | val_acc=0.9291 | macroP=0.9259 | macroR=0.9215 | macroF1=0.9232\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 | loss=1.2045 | val_acc=0.9307 | macroP=0.9272 | macroR=0.9234 | macroF1=0.9249\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 | loss=1.1628 | val_acc=0.9325 | macroP=0.9296 | macroR=0.9255 | macroF1=0.9271\n",
      "  ✓ Saved new best EMA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 | loss=1.1528 | val_acc=0.9319 | macroP=0.9288 | macroR=0.9248 | macroF1=0.9264\n",
      "\n",
      "============================================================\n",
      "FINAL VALIDATION (BEST EMA)\n",
      "============================================================\n",
      "Total trainable parameters: 278,912\n",
      "Accuracy:        0.932498\n",
      "Macro-Precision: 0.929580\n",
      "Macro-Recall:    0.925461\n",
      "Macro-F1:        0.927060\n",
      "\n",
      "Confusion Matrix:\n",
      " [[340   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  6 119   1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 245   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0 328   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 144   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   1   0 164   3   1   0   1   3   7   0   1   1   3]\n",
      " [  0   0   0   0   1   4 158   1   3   1   3   5   2   0   1   0]\n",
      " [  0   0   0   0   0   2   3 147   3   0   0   6   0   1   0   0]\n",
      " [  2   0   0   0   0   6   0   3 210   1   4   6   3   0   3   0]\n",
      " [  0   0   0   0   0   0   0   0   0 148   9   1   1   2   1   0]\n",
      " [  2   0   0   1   1   0   0   1   0   8 165   1   0   0   2   0]\n",
      " [  0   1   2   0   0   3   2   5   4   2   1 334   0   1   2   0]\n",
      " [  1   0   1   1   1   1   7   1   1   4   2   3 155   3   1   3]\n",
      " [  0   0   0   0   0   1   1   0   0   2   0   1   3 104   0   1]\n",
      " [  2   1   0   0   1   5   2   0   0   2   2   5   0   0 143   0]\n",
      " [  0   0   0   0   0   1   0   2   1   3   2   0   2   1   0 149]]\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer Test: 100%|██████████| 455/455 [04:01<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /kaggle/working/submission96.csv\n",
      "   id  target\n",
      "0   0       3\n",
      "1   1       8\n",
      "2   2       8\n",
      "3   3       0\n",
      "4   4      11\n",
      "5   5      10\n",
      "6   6       3\n",
      "7   7       8\n",
      "8   8       4\n",
      "9   9       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Hyperparameters\n",
    "    IMG_SIZE = 96\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_WORKERS = 2\n",
    "    VAL_RATIO = 0.15\n",
    "\n",
    "    EPOCHS = 50\n",
    "    LR = 1e-3\n",
    "    WD = 1e-4\n",
    "    MAX_LR = 3e-3\n",
    "    MIX_ALPHA = 0.3\n",
    "    LABEL_SMOOTH = 0.10\n",
    "    GRAD_CLIP = 1.0\n",
    "\n",
    "    # Load and split data\n",
    "    full_df = pd.read_csv(TRAIN_META)\n",
    "    train_df, val_df = train_test_split(\n",
    "        full_df, test_size=VAL_RATIO, random_state=SEED, stratify=full_df[\"target\"]\n",
    "    )\n",
    "\n",
    "    # Create datasets\n",
    "    ds_train = MusicTripleDataset(TRAIN_META, img_size=IMG_SIZE, is_train=True,  df=train_df)\n",
    "    ds_val   = MusicTripleDataset(TRAIN_META, img_size=IMG_SIZE, is_train=False, df=val_df)\n",
    "\n",
    "    # Create data loaders\n",
    "    loader_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    loader_val   = DataLoader(ds_val,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    # Initialize model\n",
    "    model = TripleBranchNet(num_classes=16).to(DEVICE)\n",
    "    n_params = count_params(model)\n",
    "    print(f\"Total trainable parameters: {n_params:,}\")\n",
    "    assert n_params <= 500_000, f\"Param limit exceeded: {n_params}\"\n",
    "\n",
    "    # Setup optimizer and scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=MAX_LR, epochs=EPOCHS, steps_per_epoch=len(loader_train),\n",
    "        pct_start=0.3, div_factor=10, final_div_factor=100\n",
    "    )\n",
    "\n",
    "    # Initialize EMA\n",
    "    ema = EMA(model, decay=0.999)\n",
    "\n",
    "    best_f1 = -1.0\n",
    "    best_state = None\n",
    "\n",
    "    print(\"\\nStarting training...\\n\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # Train for one epoch\n",
    "        loss = train_one_epoch(\n",
    "            model, loader_train, optimizer, scheduler, ema,\n",
    "            mix_alpha=MIX_ALPHA, label_smoothing=LABEL_SMOOTH, grad_clip=GRAD_CLIP\n",
    "        )\n",
    "\n",
    "        # Validate using EMA weights\n",
    "        cur = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        ema.apply_to(model)\n",
    "        acc, prec, rec, f1, cm = evaluate(model, loader_val)\n",
    "        model.load_state_dict(cur, strict=True)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{EPOCHS} | loss={loss:.4f} | val_acc={acc:.4f} | macroP={prec:.4f} | macroR={rec:.4f} | macroF1={f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in ema.shadow.items()}\n",
    "            torch.save(best_state, \"/kaggle/working/best_model_ema.pth\")\n",
    "            print(\"  ✓ Saved new best EMA model\")\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL VALIDATION (BEST EMA)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_state, strict=True)\n",
    "    acc, prec, rec, f1, cm = evaluate(model, loader_val)\n",
    "    \n",
    "    print(f\"Total trainable parameters: {n_params:,}\")\n",
    "    print(f\"Accuracy:        {acc:.6f}\")\n",
    "    print(f\"Macro-Precision: {prec:.6f}\")\n",
    "    print(f\"Macro-Recall:    {rec:.6f}\")\n",
    "    print(f\"Macro-F1:        {f1:.6f}\")\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    # Test inference and submission\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(TEST_META)\n",
    "    ds_test = MusicTripleDataset(TEST_META, img_size=IMG_SIZE, is_train=False, df=test_df)\n",
    "    loader_test = DataLoader(ds_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader_test, desc=\"Infer Test\"):\n",
    "            x1, x2, x3 = batch\n",
    "            x1, x2, x3 = x1.to(DEVICE), x2.to(DEVICE), x3.to(DEVICE)\n",
    "            logits = model(x1, x2, x3)\n",
    "            preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "    preds = np.concatenate(preds)[:len(test_df)]\n",
    "\n",
    "    # Create submission file\n",
    "    sub = pd.DataFrame({\"id\": test_df[\"id\"].values, \"target\": preds.astype(int)})\n",
    "    out_path = \"/kaggle/working/submission96.csv\"\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(\"Saved:\", out_path)\n",
    "    print(sub.head(10))\n",
    "\n",
    "# Execute\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9396973,
     "sourceId": 14708279,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
